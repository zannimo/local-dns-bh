dhcp_option.tf 
resource "aws_vpc_dhcp_options" "main" {
  domain_name = var.domain_name

  # My DNS server (BIND9) will be the primary one
  # AWS DNS resolver will a fallback for AWS services
  domain_name_servers = [
    var.dns_server_ip,
    "AmazonProvidedDNS" 
  ]

  tags = {
    Name    = "${var.project_name}-dhcp-options"
    Project = var.project_name
  }
}

resource "aws_vpc_dhcp_options_association" "main" {
  vpc_id          = aws_vpc.main.id
  dhcp_options_id = aws_vpc_dhcp_options.main.id
}

iam.tf 
resource "aws_iam_role" "client_ssm" {
  name = "${var.project_name}-client-ssm-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "ec2.amazonaws.com"
      }
    }]
  })
  
  tags = {
    Name    = "${var.project_name}-client-ssm-role"
    Project = var.project_name
  }
}

resource "aws_iam_role_policy_attachment" "client_ssm_core" {
  role       = aws_iam_role.client_ssm.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
}

instances.tf 
resource "aws_instance" "bastion" {
  ami                    = var.ami_id
  instance_type          = "t2.micro"
  subnet_id              = aws_subnet.public.id
  vpc_security_group_ids = [aws_security_group.bastion.id]
  key_name               = var.key_name # To load the public key uploaded in AWS EC2 into this instance for SSH access
  associate_public_ip_address = true # != EIP. It will always change upon reboot of the instance. Considering adding an EIP later

  # User data to set hostname
  user_data = <<-EOF
              #!/bin/bash
              hostnamectl set-hostname bastion.${var.domain_name}
              EOF

  tags = {
    Name    = "${var.project_name}-bastion"
    Project = var.project_name
    Role    = "Bastion"
  }
}


resource "aws_instance" "dns_server" {
  ami                    = var.ami_id
  instance_type          = "t2.micro"
  subnet_id              = aws_subnet.private.id
  vpc_security_group_ids = [aws_security_group.dns_server.id]
  key_name               = var.key_name # To load the public key uploaded in AWS EC2 into this instance for SSH access
  private_ip = var.dns_server_ip
  
  # User data to set hostname
  user_data = <<-EOF
              #!/bin/bash
              hostnamectl set-hostname ns1.${var.domain_name}
              echo "DNS server will be configured with BIND9"
              EOF

  tags = {
    Name    = "${var.project_name}-dns-server"
    Project = var.project_name
    Role    = "DNS"
  }
}

resource "aws_instance" "client1" {
  ami                    = var.ami_id
  instance_type          = "t2.micro"
  subnet_id              = aws_subnet.private.id
  vpc_security_group_ids = [aws_security_group.clients.id]

  # User data to set hostname
  user_data = <<-EOF
              #!/bin/bash
              hostnamectl set-hostname client1.${var.domain_name}
              EOF
  
  iam_instance_profile = aws_iam_instance_profile.client_ssm.name

  tags = {
    Name    = "${var.project_name}-client1"
    Project = var.project_name
    Role    = "Client"
  }
   

  # Ensure DNS server is running before clients (not strictly needed, but in case instances need to rely on DNS for installs or updates)
  depends_on = [
    aws_instance.dns_server,
    aws_iam_instance_profile.client_ssm
    ]
}


resource "aws_instance" "client2" {
  ami                    = var.ami_id
  instance_type          = "t2.micro"
  subnet_id              = aws_subnet.private.id
  vpc_security_group_ids = [aws_security_group.clients.id]

  # User data to set hostname
  user_data = <<-EOF
              #!/bin/bash
              hostnamectl set-hostname client2.${var.domain_name}
              EOF
  
  iam_instance_profile = aws_iam_instance_profile.client_ssm.name

  tags = {
    Name    = "${var.project_name}-client2"
    Project = var.project_name
    Role    = "Client"
  }

  # Ensure DNS server is running before clients (not strictly needed, but in case instances need to rely on DNS for installs or updates)
  depends_on = [aws_instance.dns_server,
  aws_iam_instance_profile.client_ssm
  ]
}

resource "aws_iam_instance_profile" "client_ssm" {
  name = "${var.project_name}-client-ssm-profile"
  role = aws_iam_role.client_ssm.name
  
  tags = {
    Name    = "${var.project_name}-client-ssm-profile"
    Project = var.project_name
  }
}

provider.tf 
terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region  = var.aws_region
  profile = "local-dns-bh-project"
  
  default_tags {
    tags = {
      Project     = "local-dns-bh"
    }
  }
}

data "aws_availability_zones" "available" {
  state = "available"
}

security_groups.tf 
resource "aws_security_group" "bastion" {
  name_prefix = "${var.project_name}-bastion-"
  description = "Security group for bastion host"
  vpc_id      = aws_vpc.main.id
  ingress {
    description = "SSH from allowed IPs"
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = [var.my_ip]
  }

  egress {
    description = "SSH to DNS server"
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["${var.dns_server_ip}/32"] 
  }

  egress {
    description = "HTTPS for package updates"
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]  # Ubuntu repos
  }

  egress {
    description = "HTTP for package updates"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"] # Ubuntu repos
  }

  egress {
    description = "DNS UDP to DNS server"
    from_port   = 53
    to_port     = 53
    protocol    = "udp"
    cidr_blocks = ["${var.dns_server_ip}/32"]
  }

  egress {
    description = "DNS TCP to DNS server"
    from_port   = 53
    to_port     = 53
    protocol    = "tcp"
    cidr_blocks = ["${var.dns_server_ip}/32"]
  }

    egress {
    description = "NTP time sync to Amazon Time Sync Service"
    from_port   = 123
    to_port     = 123
    protocol    = "udp"
    cidr_blocks = ["169.254.169.123/32"]
    }
    
    tags = {
    Name    = "${var.project_name}-bastion-sg"
    Project = var.project_name
  }
}

resource "aws_security_group" "dns_server" {
  name_prefix = "${var.project_name}-dns-"
  description = "Security group for DNS server"
  vpc_id      = aws_vpc.main.id

  # Allow SSH from bastion host
  ingress {
    description     = "SSH from bastion"
    from_port       = 22
    to_port         = 22
    protocol        = "tcp"
    security_groups = [aws_security_group.bastion.id]
  }

  ingress {
    description = "DNS UDP from VPC"
    from_port   = 53
    to_port     = 53
    protocol    = "udp"
    cidr_blocks = [var.vpc_cidr]
  }

  ingress {
    description = "DNS TCP from VPC"
    from_port   = 53
    to_port     = 53
    protocol    = "tcp"
    cidr_blocks = [var.vpc_cidr]
  }

  egress {
    description = "DNS forwarding to public resolver"
    from_port   = 53
    to_port     = 53
    protocol    = "udp"
    cidr_blocks = ["8.8.8.8/32", "8.8.4.4/32"]  # Google DNS
  }

  egress {
    description = "DNS TCP forwarding to public resolver"
    from_port   = 53
    to_port     = 53
    protocol    = "tcp"
    cidr_blocks = ["8.8.8.8/32", "8.8.4.4/32"]
  }

  egress {
    description = "HTTP for package updates"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
   }

  egress {
    description = "NTP time sync"
    from_port   = 123
    to_port     = 123
    protocol    = "udp"
    cidr_blocks = ["169.254.169.123/32"]  # AWS Time Sync Service
  }

    tags = {
    Name    = "${var.project_name}-dns-sg"
    Project = var.project_name
  }
}

resource "aws_security_group" "clients" {
  name_prefix = "${var.project_name}-clients-"
  description = "Security group for client instances"
  vpc_id      = aws_vpc.main.id

  # No ingress rules: using SSM Session Manager for access

  egress {
    description = "DNS UDP to DNS server"
    from_port   = 53
    to_port     = 53
    protocol    = "udp"
    cidr_blocks = ["${var.dns_server_ip}/32"]
  }

  egress {
    description = "DNS TCP to DNS server"
    from_port   = 53
    to_port     = 53
    protocol    = "tcp"
    cidr_blocks = ["${var.dns_server_ip}/32"]
  }

  egress {
    description = "HTTPS for testing/updates"
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    description = "HTTP for testing/updates"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    description = "NTP time sync"
    from_port   = 123
    to_port     = 123
    protocol    = "udp"
    cidr_blocks = ["169.254.169.123/32"]
  }

  tags = {
    Name    = "${var.project_name}-clients-sg"
    Project = var.project_name
  }
}

resource "aws_security_group" "vpc_endpoint" {
  name_prefix = "${var.project_name}-vpc_endpoint-"
  description = "Security group for VPC endpoint"
  vpc_id      = aws_vpc.main.id

  tags = {
    Name    = "${var.project_name}-vpc_endpoint-sg"
    Project = var.project_name
  }
}

  # Separate rule to avoid Cycle error
  resource "aws_security_group_rule" "clients_to_vpc_endpoint" {
  type                     = "egress"
  from_port                = 443
  to_port                  = 443
  protocol                 = "tcp"
  security_group_id        = aws_security_group.clients.id
  source_security_group_id = aws_security_group.vpc_endpoint.id
  description              = "VPC endpoint access"
}

# Separate rule: Allow VPC endpoint to accept traffic from clients
resource "aws_security_group_rule" "vpc_endpoint_from_clients" {
  type                     = "ingress"
  from_port                = 443
  to_port                  = 443
  protocol                 = "tcp"
  security_group_id        = aws_security_group.vpc_endpoint.id
  source_security_group_id = aws_security_group.clients.id
  description              = "From clients"
}

terraform.tvars:

aws_region: eu-central-1
project_name: local-dns-bh
vpc_cidr: 10.0.0.0/16
public_subnet_cidr: 10.0.1.0/24
private_subnet_cidr: 10.0.2.0/24
dns_server_ip: 10.0.2.10
dns_forwarders: ["8.8.8.8", "8.8.4.4"]
domain_name: lab.luigi
my_ip: 192.168.1.100
key_name: local-dns-bh-key
ami_id: ami-0854d4f8e4bd6b834

variables.tf:

variable "aws_region" {
  description = "AWS region for resources"
  type        = string
  default     = "eu-central-1"
}

variable "project_name" {
  description = "Project name for resource naming"
  type        = string
  default     = "local-dns-bh"
}

variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
  default     = "10.0.0.0/16"
}

variable "public_subnet_cidr" {
  description = "CIDR block for public subnet"
  type        = string
  default     = "10.0.1.0/24"
}

variable "private_subnet_cidr" {
  description = "CIDR block for private subnet"
  type        = string
  default     = "10.0.2.0/24"
}

variable "dns_server_ip" {
  description = "Static IP for DNS server"
  type        = string
  default     = "10.0.2.10"
}

variable "dns_forwarders" {
  description = "External DNS servers for forwarding"
  type        = list(string)
  default     = ["8.8.8.8", "8.8.4.4"]  # Google DNS
}

variable "domain_name" {
  description = "Internal domain name for the network"
  type        = string
  default     = "lab.luigi"
}

variable "my_ip" {
  description = "My public IP for SSH access"
  type        = string
}

variable "key_name" {
  description = "Name of the SSH key pair for EC2 access"
  type        = string
}

variable "ami_id" {
  description = "Amazon Linux 2023 kernel-6.1 AMI"
  type        = string
  default     = "ami-0854d4f8e4bd6b834"
}

vpc.tf:
resource "aws_vpc" "main" {
  cidr_block = var.vpc_cidr

  # Enable DNS support and hostnames
  enable_dns_support   = true
  enable_dns_hostnames = true

  tags = {
    Name    = "${var.project_name}-vpc"
    Project = var.project_name
  }
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = {
    Name    = "${var.project_name}-igw"
    Project = var.project_name
  }
}

resource "aws_subnet" "public" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = var.public_subnet_cidr
  availability_zone       = data.aws_availability_zones.available.names[0]
  map_public_ip_on_launch = true

  tags = {
    Name    = "${var.project_name}-public-subnet"
    Project = var.project_name
    Tier    = "Public"
  }
}

resource "aws_subnet" "private" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = var.private_subnet_cidr
  availability_zone = data.aws_availability_zones.available.names[0]

  tags = {
    Name    = "${var.project_name}-private-subnet"
    Project = var.project_name
    Tier    = "Private"
  }
}

resource "aws_nat_gateway" "main" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public.id

  tags = {
    Name    = "${var.project_name}-nat-gateway"
    Project = var.project_name
  }

  depends_on = [
  aws_internet_gateway.main,
  aws_eip.nat
  ]
}


resource "aws_eip" "nat" {
  domain = "vpc"
  tags = {
    Name    = "${var.project_name}-nat-eip"
    Project = var.project_name
  }
  depends_on = [aws_internet_gateway.main]
}

# Route Table - Public
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  tags = {
    Name    = "${var.project_name}-public-rt"
    Project = var.project_name
  }
}

# Route Table - Private
resource "aws_route_table" "private" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.main.id
  }

  tags = {
    Name    = "${var.project_name}-private-rt"
    Project = var.project_name
  }
}

resource "aws_vpc_endpoint" "ssm" {
  vpc_id            = aws_vpc.main.id
  service_name      = "com.amazonaws.${var.aws_region}.ssm"
  vpc_endpoint_type = "Interface"
  subnet_ids        = [aws_subnet.private.id]
  security_group_ids = [aws_security_group.vpc_endpoint.id]
  private_dns_enabled = true
}

resource "aws_vpc_endpoint" "ec2messages" {
  vpc_id              = aws_vpc.main.id
  service_name        = "com.amazonaws.${var.aws_region}.ec2messages"
  vpc_endpoint_type   = "Interface"
  subnet_ids          = [aws_subnet.private.id]
  security_group_ids  = [aws_security_group.vpc_endpoint.id]
  private_dns_enabled = true

  tags = {
    Name    = "${var.project_name}-ec2messages-endpoint"
    Project = var.project_name
  }
}

resource "aws_vpc_endpoint" "ssmmessages" {
  vpc_id              = aws_vpc.main.id
  service_name        = "com.amazonaws.${var.aws_region}.ssmmessages"
  vpc_endpoint_type   = "Interface"
  subnet_ids          = [aws_subnet.private.id]
  security_group_ids  = [aws_security_group.vpc_endpoint.id]
  private_dns_enabled = true

  tags = {
    Name    = "${var.project_name}-ssmmessages-endpoint"
    Project = var.project_name
  }
}


# Route Table Association - Public Subnet
resource "aws_route_table_association" "public" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public.id
}

# Route Table Association - Private Subnet
resource "aws_route_table_association" "private" {
  subnet_id      = aws_subnet.private.id
  route_table_id = aws_route_table.private.id
}

output.tf:

output "bastion_public_ip" {
  description = "Automatic public IP address of bastion host"
  value       = aws_instance.bastion.public_ip
}


output "dns_server_ip" {
  description = "Private IP of DNS server"
  value       = aws_instance.dns_server.private_ip
}

output "client_instance_ids" {
  description = "Instance IDs for SSM access"
  value = {
    client1 = aws_instance.client1.id
    client2 = aws_instance.client2.id
  }
}

output "ssh_command" {
  description = "SSH command to connect to bastion"
  value       = "ssh -i ~/.ssh/${var.key_name}.pem ec2-user@${aws_instance.bastion.public_ip}"
}
